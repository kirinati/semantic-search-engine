{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code]\nimport pinecone\nimport streamlit as st\nfrom transformers import pipeline\nfrom sentence_transformers import SentenceTransformer\n\nPINECONE_KEY = st.secrets[\"PINECONE_KEY\"]  # app.pinecone.io\n\n@st.experimental_singleton\ndef init_pinecone():\n    pinecone.init(api_key=PINECONE_KEY, environment=\"us-west1-gcp\")  # get a free api key from app.pinecone.io\n    return pinecone.Index(\"extractive-question-answering\")\n    \n@st.experimental_singleton\ndef init_models():\n    retriever = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n    model_name = 'deepset/electra-base-squad2'\n    reader = pipeline(tokenizer=model_name, model=model_name, task='question-answering')\n    return retriever, reader\n\nst.session_state.index = init_pinecone()\nretriever, reader = init_models()\n\n\ndef card(title, context, score):\n    return st.markdown(f\"\"\"\n    <div class=\"container-fluid\">\n        <div class=\"row align-items-start\">\n             <div  class=\"col-md-12 col-sm-12\">\n                 <b>{title}</b>\n                 <br>\n                 <span style=\"color: #808080;\">\n                     <small>{context}</small>\n                     [<b>Score: </b>{score}]\n                 </span>\n             </div>\n        </div>\n     </div>\n        \"\"\", unsafe_allow_html=True)\n\nst.title(\"\")\n\nst.write(\"\"\"\n# Extractive Question Answering\nAsk me a question!\n\"\"\")\n\nst.markdown(\"\"\"\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\">\n\"\"\", unsafe_allow_html=True)\n\ndef run_query(query):\n    xq = retriever.encode([query]).tolist()\n    try:\n        xc = st.session_state.index.query(xq, top_k=3, include_metadata=True)\n    except:\n        # force reload\n        pinecone.init(api_key=PINECONE_KEY, environment=\"us-west1-gcp\")\n        st.session_state.index = pinecone.Index(\"extractive-question-answering\")\n        xc = st.session_state.index.query(xq, top_k=3, include_metadata=True)\n\n    results = []\n    for match in xc['matches']:\n        answer = reader(question=query, context=match[\"metadata\"]['context'])\n        answer[\"title\"] = match[\"metadata\"]['title']\n        answer[\"context\"] = match[\"metadata\"]['context']\n        results.append(answer)\n\n    sorted_result = sorted(results, key=lambda x: x['score'], reverse=True)\n\n    for r in sorted_result:\n        answer = r[\"answer\"]\n        context = r[\"context\"].replace(answer, f\"<mark>{answer}</mark>\")\n        title = r[\"title\"].replace(\"_\", \" \")\n        score = round(r[\"score\"], 4)\n        card(title, context, score)\n\nquery = st.text_input(\"Search!\", \"\")\n\nif query != \"\":\n    run_query(query)","metadata":{"_uuid":"dfaf6ff0-ea64-4275-a20a-e5cc90ffad06","_cell_guid":"2c76f5d0-7cd4-4a69-a79a-30606fc0de2c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}